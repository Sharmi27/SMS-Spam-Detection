{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "581d1297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.971953578336557\n",
      "Confusion Matrix:\n",
      " [[896   0]\n",
      " [ 29 109]]\n",
      "Precision: 1.0\n",
      "For  SVC\n",
      "Accuracy -  0.9758220502901354\n",
      "Precision -  0.9747899159663865\n",
      "For  NB\n",
      "Accuracy -  0.971953578336557\n",
      "Precision -  1.0\n",
      "For  RF\n",
      "Accuracy -  0.9748549323017408\n",
      "Precision -  0.9827586206896551\n",
      "For  ETC\n",
      "Accuracy -  0.9796905222437138\n",
      "Precision -  0.975609756097561\n",
      "Accuracy 0.9806576402321083\n",
      "Precision 0.946969696969697\n",
      "(4135, 3000)\n",
      "(1034, 3000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "ps= PorterStemmer()\n",
    "df= pd.read_csv('spam.csv')\n",
    "df.sample(5)\n",
    "\n",
    "\n",
    "#1. Data Cleaning\n",
    "\n",
    "#drop last 3 columns since most values are null\n",
    "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)\n",
    "#renaming the columns and we specify the names using a dictionary\n",
    "df.rename(columns={'v1':'target','v2':'text'},inplace=True)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['target'] = encoder.fit_transform(df['target'])\n",
    "df.head()\n",
    "#check for missing values\n",
    "df.isnull().sum()\n",
    "#check for duplicate values\n",
    "df.duplicated().sum()\n",
    "#remove duplicate values\n",
    "df = df.drop_duplicates(keep = 'first')\n",
    "\n",
    "df.duplicated().sum()\n",
    "\n",
    "#2. EDA: Exploratory Data Analysis\n",
    "df['target'].value_counts()\n",
    "\n",
    "#plt.pie(df['target'].value_counts(),labels=['ham','spam'],autopct=\"%0.2f\")\n",
    "\n",
    "#results of pie chart show that 87% sms are not spam and the rest 13% are spam\n",
    "#Data is unbalanced since ham >spam\n",
    "#plt.show()\n",
    "\n",
    "df['num_characters']=df['text'].apply(len)\n",
    "df.head()\n",
    "#num of words \n",
    "#nltk.download('punkt')\n",
    "df['num_words'] = df['text'].apply(lambda x:len(nltk.word_tokenize(x)))\n",
    "\n",
    "df['num_sentences'] = df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))\n",
    "\n",
    "df[['num_characters','num_words','num_sentences']].describe()\n",
    "\n",
    "#describe method on ham messages\n",
    "df[df['target'] == 0][['num_characters','num_words','num_sentences']].describe()\n",
    "\n",
    "#describe method on spam messages\n",
    "df[df['target'] == 1][['num_characters','num_words','num_sentences']].describe()\n",
    "\n",
    "#sns.heatmap(df.corr(),annot=True)\n",
    "\n",
    "#3. Data preprocessing\n",
    "##(i) Lower case\n",
    "##(ii) Tokenization\n",
    "##(iii) Removing Special Characters\n",
    "##(iv) Removing stop words and punctuations\n",
    "##(v) Stemming\n",
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "            \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "            \n",
    "    return \" \".join(y)\n",
    "\n",
    "df['transformed_text'] = df['text'].apply(transform_text)\n",
    "wc= WordCloud(width=500,height=500,min_font_size=10,background_color='white')\n",
    "spam_wc = wc.generate(df[df['target']==1]['transformed_text'].str.cat(sep=\" \"))\n",
    "# plt.figure(figsize=(15,6))\n",
    "# plt.imshow(spam_wc)\n",
    "ham_wc = wc.generate(df[df['target']==0]['transformed_text'].str.cat(sep=\" \"))\n",
    "# plt.figure(figsize=(15,6))\n",
    "# plt.imshow(ham_wc)\n",
    "df.head()\n",
    "\n",
    "spam_corpus=[]\n",
    "for msg in df[df['target']== 1]['transformed_text'].tolist():\n",
    "    for word in msg.split():\n",
    "        spam_corpus.append(word)\n",
    "len(spam_corpus)\n",
    "\n",
    "ham_corpus=[]\n",
    "for msg in df[df['target']== 0]['transformed_text'].tolist():\n",
    "    for word in msg.split():\n",
    "        ham_corpus.append(word)\n",
    "len(ham_corpus)\n",
    "\n",
    "#4. Model Building\n",
    "#Naive based algorithm\n",
    "cv = CountVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=3000)\n",
    "\n",
    "X = tfidf.fit_transform(df['transformed_text']).toarray()\n",
    "\n",
    "#appending the num_character col to X\n",
    "#X = np.hstack((X,df['num_characters'].values.reshape(-1,1)))\n",
    "\n",
    "#X = cv.fit_transform(df['transformed_text']).toarray()\n",
    "\n",
    "\n",
    "y = df['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=2)\n",
    "#gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred2 = mnb.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred2))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred2))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred2))\n",
    "\n",
    "#bnb = BernoulliNB()\n",
    "\n",
    "# gnb.fit(X_train,y_train)\n",
    "# y_pred1 = gnb.predict(X_test)\n",
    "# print(accuracy_score(y_test,y_pred1))\n",
    "# print(confusion_matrix(y_test,y_pred1))\n",
    "# print(precision_score(y_test,y_pred1))\n",
    "\n",
    "\n",
    "# bnb.fit(X_train,y_train)\n",
    "# y_pred3 = bnb.predict(X_test)\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred3))\n",
    "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred3))\n",
    "# print(\"Precision:\", precision_score(y_test, y_pred3))\n",
    "\n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "#mnb = MultinomialNB()\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "\n",
    "\n",
    "clfs = {\n",
    "  'SVC' : svc,\n",
    "  'NB': mnb, \n",
    "  'RF': rfc,\n",
    "  'ETC': etc\n",
    "}\n",
    "\n",
    "def train_classifier(clf,X_train,y_train,X_test,y_test):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    \n",
    "    return accuracy,precision\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    current_accuracy,current_precision = train_classifier(clf, X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    print(\"For \",name)\n",
    "    print(\"Accuracy - \",current_accuracy)\n",
    "    print(\"Precision - \",current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "\n",
    "performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)\n",
    "performance_df1 = pd.melt(performance_df, id_vars = \"Algorithm\")\n",
    "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_max_ft_3000':accuracy_scores,'Precision_max_ft_3000':precision_scores}).sort_values('Precision_max_ft_3000',ascending=False)\n",
    "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_scaling':accuracy_scores,'Precision_scaling':precision_scores}).sort_values('Precision_scaling',ascending=False)\n",
    "new_df = performance_df.merge(temp_df,on='Algorithm')\n",
    "new_df_scaled = new_df.merge(temp_df,on='Algorithm')\n",
    "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_num_chars':accuracy_scores,'Precision_num_chars':precision_scores}).sort_values('Precision_num_chars',ascending=False)\n",
    "new_df_scaled.merge(temp_df,on='Algorithm')\n",
    "\n",
    "# Voting Classifier\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0,probability=True)\n",
    "#mnb = MultinomialNB()\n",
    "#etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "\n",
    "\n",
    "voting = VotingClassifier(estimators=[('svm', svc), ('nb', mnb), ('et', etc)],voting='soft')\n",
    "\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "y_pred= voting.predict(X_test)\n",
    "\n",
    "#Applying Stacking\n",
    "estimators=[('svm', svc), ('nb', mnb), ('et', etc)]\n",
    "final_estimator=RandomForestClassifier()\n",
    "clf= StackingClassifier(estimators=estimators,final_estimator=final_estimator)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision\",precision_score(y_test,y_pred))\n",
    "\n",
    "\n",
    "pickle.dump(tfidf,open('vectorizer.pkl','wb'))\n",
    "pickle.dump(mnb,open('model.pkl','wb'))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "#5. Evaluation\n",
    "#6. Improvements\n",
    "#7. Website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5df6d17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.24.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp39-cp39-win_amd64.whl (8.4 MB)\n",
      "     ---------------------------------------- 8.4/8.4 MB 10.1 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ------------------------------------- 298.0/298.0 kB 18.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.6.3)\n",
      "Installing collected packages: joblib, scikit-learn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Sharmi Dev Gupta\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\Lib\\\\site-packages\\\\~klearn\\\\.libs\\\\vcomp140.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.1\n",
      "    Uninstalling joblib-1.0.1:\n",
      "      Successfully uninstalled joblib-1.0.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95a0309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.2.2-cp39-cp39-win_amd64.whl (153 kB)\n",
      "     -------------------------------------- 153.1/153.1 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from wordcloud) (9.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from wordcloud) (3.6.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from wordcloud) (1.20.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->wordcloud) (20.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->wordcloud) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->wordcloud) (1.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e67a41ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sharmi Dev\n",
      "[nltk_data]     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ac371d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "     -------------------------------------- 293.3/293.3 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (1.2.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (3.6.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (1.20.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (20.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.6)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.25->seaborn) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a8d4605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.1/77.1 kB ? eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.3.23-cp39-cp39-win_amd64.whl (267 kB)\n",
      "     ------------------------------------- 268.0/268.0 kB 17.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.3.23 tqdm-4.65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sharmi dev gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf44944",
   "metadata": {},
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50245b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
